optimizer : {
  type: AdamW,
  part: all,
  kwargs: {
  lr : 0.001,
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/ShapeNet-55_withnormal.yaml,
            others: {subset: 'train', npoints: 2048, aug_type: ['norm'], corrupt_type: ['clean']}},
  val : { _base_: cfgs/dataset_configs/ShapeNet-55_withnormal.yaml,
            others: {subset: 'test', npoints: 2048, aug_type: ['norm'], corrupt_type: ['clean']}},
  test : { _base_: cfgs/dataset_configs/ShapeNet-55_withnormal.yaml,
            others: {subset: 'test', npoints: 2048, aug_type: ['norm'], corrupt_type: ['clean']}}}

model: {
  NAME: Point_M2AE,
  corrupt_type: ['affine_r3', 'Drop-Patch'],
  mask_ratio: 0.8,
  # tokenizers
  group_sizes: [16, 8, 8],
  num_groups: [512, 256, 64],
  # hierarchical encoder
  encoder_depths: [5, 5, 5],
  encoder_dims: [96, 192, 384],
  local_radius: [0.32, 0.64, 1.28],  # disabled for pre-training
  # hierarchical decoder
  decoder_depths: [1, 1],
  decoder_dims: [384, 192],
  decoder_up_blocks: [1, 1],
  # others
  drop_path_rate: 0.1,
  num_heads: 6,}

npoints: 2048
total_bs: 128
step_per_update: 1
max_epoch: 300
normal_weight: 0.01
loss_type: 'xyznormal'

#model : {
#  NAME: Point_M2AE,
#  corrupt_type: ['Drop-Patch'],
#  group_size: 32,
#  num_group: 64,
#  loss: cdl2,
#  transformer_config: {
#    rand_ratio: 'True',  ## random sampled from [0.5, 0.8]
#    mask_ratio: 0.6,     ## not used actually.
#    mask_type: 'rand',
#    trans_dim: 384,
#    encoder_dims: 384,
#    depth: 12,
#    drop_path_rate: 0.1,
#    num_heads: 6,
#    decoder_depth: 4,
#    decoder_num_heads: 6,
#  },
#}
#
#normal_weight: 0.0
#npoints: 1024
#total_bs : 128
#step_per_update : 1
#max_epoch : 300
#loss_type: 'xyz'